{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## GPU Puzzles in CUDA C++\n",
        "By Devin Shah - [@devinshah16](https://twitter.com/DevinShah16)\n",
        "\n",
        "Puzzles adapted from [Sasha Rush](http://rush-nlp.com/)\n",
        "\n",
        "GPUs are pretty cool.\n",
        "\n",
        "This notebook is a bit more of an advanced attempt to teach GPU programming interactively. Instead of using Python bindings (through Numba), we will be directly working with CUDA C++ bindings. In this notebook, we will just be focusing on the kernels, but in a later video, I will walk through how to instantiate the kernels, which is a bit harder than using Numba's built in executor.\n",
        "\n",
        "I recommend doing Sasha's notebook first, as the visualization are much clearer and will help build intuition.\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/srush/GPU-Puzzles/blob/main/GPU_puzzlers.ipynb)\n",
        "\n",
        "Make your own copy of this notebook in Colab, turn on GPU mode in the settings (`Runtime / Change runtime type`, then set `Hardware accelerator` to `GPU`), and\n",
        "then get to coding.\n",
        "\n",
        "Read the [CUDA C++ bindings guide ](https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf)"
      ],
      "metadata": {
        "id": "x-jiSROElcdy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTDAhBvMKWcM",
        "outputId": "8073646b-7853-4567-a0cb-98f42ca37b4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puzzle 2 - Zip\n",
        "Implement a kernel that adds together each position of `a` and `b` and stores it in `out`. You have 1 thread per position."
      ],
      "metadata": {
        "id": "2bvkLWQ1sQvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile zip.cu\n",
        "#include <iostream>\n",
        "#include <cassert>\n",
        "\n",
        "__global__ void VecAdd(float* A, float* B, float* C) {\n",
        "  int i = threadIdx.x;\n",
        "  C[i] = A[i] + B[i];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 3;\n",
        "    float A[N], B[N], C[N];\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        A[i] = static_cast<float>(i);\n",
        "        B[i] = static_cast<float>(N - i);\n",
        "    }\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "\n",
        "    cudaMalloc(&d_A, sizeof(float) * N);\n",
        "    cudaMalloc(&d_B, sizeof(float) * N);\n",
        "    cudaMalloc(&d_C, sizeof(float) * N);\n",
        "\n",
        "    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    VecAdd<<<1, N>>>(d_A, d_B, d_C);\n",
        "\n",
        "    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "      assert(C[i] == A[i] + B[i]);\n",
        "    }\n",
        "\n",
        "    std::cout << \"Vector addition successful!\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtracF3EK1Gz",
        "outputId": "c278349b-ba60-4fd6-beca-e7d134a2de86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing zip.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc zip.cu -o zip\n",
        "!./zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNJ9YSWFK-aC",
        "outputId": "be59e299-c85f-4f81-98d0-2803606a3ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector addition successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile map.cu\n",
        "#include <iostream>\n",
        "#include <cassert>\n",
        "\n",
        "__global__ void ScalarAdd(float* A, float* C) {\n",
        "  int i = threadIdx.x;\n",
        "  C[i] = A[i] + 10;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int N = 3;\n",
        "  float A[N], C[N];\n",
        "\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    A[i] = static_cast<float>(i);\n",
        "  }\n",
        "\n",
        "  float *d_A, *d_C;\n",
        "\n",
        "  cudaMalloc(&d_A, N * sizeof(float));\n",
        "  cudaMalloc(&d_C, N * sizeof(float));\n",
        "\n",
        "  cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  ScalarAdd<<<1, N>>>(d_A, d_C);\n",
        "\n",
        "  cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(d_A);\n",
        "  cudaFree(d_C);\n",
        "\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    assert(C[i] == A[i] + 10);\n",
        "  }\n",
        "\n",
        "  std::cout << \"Scalar addition is successful!\" << std::endl;\n",
        "\n",
        "  return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APe2TGgvL24U",
        "outputId": "9896f531-8a7e-434b-bfdc-32aba5da4bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing map.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc map.cu -o map\n",
        "!./map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN3WsE-RcDdW",
        "outputId": "5a2180e0-7c1b-47e0-c4be-6e4e1d00c6a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scalar addition is successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile guards.cu\n",
        "#include <iostream>\n",
        "#include <cassert>\n",
        "\n",
        "__global__ void Guards(float* A, float* C, float size) {\n",
        "  int i = threadIdx.x;\n",
        "  if (i < size) {\n",
        "    C[i] = A[i] + 10;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int size = 3;\n",
        "  float A[size], C[size];\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    A[i] = static_cast<float>(i);\n",
        "  }\n",
        "\n",
        "  float *d_A, *d_C;\n",
        "\n",
        "  cudaMalloc(&d_A, size * sizeof(float));\n",
        "  cudaMalloc(&d_C, size * sizeof(float));\n",
        "\n",
        "  cudaMemcpy(d_A, A, size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  Guards<<<1, 10>>>(d_A, d_C, size);\n",
        "\n",
        "  cudaMemcpy(C, d_C, size * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(d_A);\n",
        "  cudaFree(d_C);\n",
        "\n",
        "  for (int i = 0; i < size; i++){\n",
        "    assert(C[i] == A[i] + 10);\n",
        "  }\n",
        "\n",
        "  std::cout << \"Guards successful!\" << std::endl;\n",
        "\n",
        "  return 0;\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbDIwNWEcdOg",
        "outputId": "492f616a-cdf6-4e6d-886b-2ab5dac85972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing guards.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc guards.cu -o guards\n",
        "!./guards\n",
        "!compute-sanitizer ./guards"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Rkxc_9nKvxR",
        "outputId": "8a4a0eb5-c909-4014-f2d5-6a41f730700b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guards successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Guards successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile map_2d.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cassert>\n",
        "\n",
        "__global__ void Map2D(float* A, float* C, float size) {\n",
        "  int local_i = threadIdx.x;\n",
        "  int local_j = threadIdx.y;\n",
        "\n",
        "  int index = local_i * size + local_j;\n",
        "  if (local_i < size && local_j < size) {\n",
        "    C[index] = A[index] + 10;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "  const int size = 4;\n",
        "  float A[size][size], C[size][size];\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    for (int j = 0; j < size; j++) {\n",
        "      A[i][j] = static_cast<float>(i) + static_cast<float>(j);\n",
        "    }\n",
        "  }\n",
        "\n",
        "  float *d_A, *d_C;\n",
        "\n",
        "  cudaMalloc(&d_A, (size * size) * sizeof(float));\n",
        "  cudaMalloc(&d_C, (size * size) * sizeof(float));\n",
        "\n",
        "  dim3 blockDim(size, size);\n",
        "\n",
        "  cudaMemcpy(d_A, A, (size * size) * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  Map2D<<<1, blockDim>>>(d_A, d_C, size);\n",
        "\n",
        "  cudaMemcpy(C, d_C, (size * size) * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(d_A);\n",
        "  cudaFree(d_C);\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    for (int j = 0; j < size; j++) {\n",
        "      assert(C[i][j] == A[i][j] + 10);\n",
        "    }\n",
        "  }\n",
        "\n",
        "  std::cout << \"2D mapping successful\" << std::endl;\n",
        "  return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEMg4j3TK0xM",
        "outputId": "4349fcb5-c7ed-433e-cf5e-28848bd823c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing map_2d.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc map_2d.cu -o map_2d\n",
        "!./map_2d\n",
        "!compute-sanitizer ./map_2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48BWBqo1OB91",
        "outputId": "4a37bf67-a2c3-46d2-c2ce-135907439352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D mapping successful\n",
            "========= COMPUTE-SANITIZER\n",
            "2D mapping successful\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile broadcast.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cassert>\n",
        "\n",
        "__global__ void Broadcast(float* A, float* B, float* C, int size) {\n",
        "  int local_i = threadIdx.x;\n",
        "  int local_j = threadIdx.y;\n",
        "\n",
        "  int index = local_i * size + local_j;\n",
        "  if (local_i < size && local_j < size) {\n",
        "    C[index] = A[local_i] + B[local_j];\n",
        "  }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "  const int size = 4;\n",
        "  float A[size][1], B[1][size], C[size][size];\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    A[i][0] = static_cast<float>(i);\n",
        "  }\n",
        "\n",
        "  for (int j = 0; j < size; j++) {\n",
        "    B[0][j] = static_cast<float>(j);\n",
        "  }\n",
        "\n",
        "  float *d_A, *d_B, *d_C;\n",
        "\n",
        "  cudaMalloc(&d_A, size * sizeof(float));\n",
        "  cudaMalloc(&d_B, size * sizeof(float));\n",
        "  cudaMalloc(&d_C, (size * size) * sizeof(float));\n",
        "\n",
        "  cudaMemcpy(d_A, A, size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_B, B, size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  dim3 blockDim(size, size);\n",
        "\n",
        "  Broadcast<<<1, blockDim>>>(d_A, d_B, d_C, size);\n",
        "\n",
        "  cudaMemcpy(C, d_C, (size * size) * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(d_A);\n",
        "  cudaFree(d_B);\n",
        "  cudaFree(d_C);\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    for (int j = 0; j < size; j++) {\n",
        "      assert(C[i][j] == A[i][0] + B[0][j]);\n",
        "    }\n",
        "  }\n",
        "\n",
        "  std::cout << \"Broadcast successful\" << std::endl;\n",
        "  return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a46tpsGBZt9F",
        "outputId": "def1b268-9641-420c-9def-5dbb087065aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing broadcast.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc broadcast.cu -o broadcast\n",
        "!./broadcast\n",
        "!compute-sanitizer ./broadcast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRzuxO8Dx-C-",
        "outputId": "30237f8c-6b74-41fa-c2f7-d04fee4a16e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Broadcast successful\n",
            "========= COMPUTE-SANITIZER\n",
            "Broadcast successful\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile blocks.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cassert>\n",
        "\n",
        "__global__ void Blocks(float* A, float* C, float size) {\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (i < size) {\n",
        "    C[i] = A[i] + 10;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int size = 5;\n",
        "  float A[size], C[size];\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    A[i] = static_cast<float>(i);\n",
        "  }\n",
        "\n",
        "  float *d_A, *d_C;\n",
        "\n",
        "  cudaMalloc(&d_A, size * sizeof(float));\n",
        "  cudaMalloc(&d_C, size * sizeof(float));\n",
        "\n",
        "  cudaMemcpy(d_A, A, size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  int threadsPerBlock = size - 1;\n",
        "  int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "  Blocks<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_C, size);\n",
        "\n",
        "  cudaMemcpy(C, d_C, size * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(d_A);\n",
        "  cudaFree(d_C);\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    assert(C[i] == A[i] + 10);\n",
        "  }\n",
        "\n",
        "  std::cout << \"Blocks successful!\" << std::endl;\n",
        "  return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBTmIFEDyC5N",
        "outputId": "0239922f-4fa1-454a-cddf-26ecaea9dce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing blocks.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc blocks.cu -o blocks\n",
        "!./blocks\n",
        "!compute-sanitizer ./blocks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OxzvRsjXtKo",
        "outputId": "f832ed8d-cfee-4a5c-e8b1-21bef09a1e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blocks successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Blocks successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile map2d_block.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cassert>\n",
        "\n",
        "__global__ void Map2DBlock(float* A, float* C, float size) {\n",
        "  int local_i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int local_j = blockDim.y * blockIdx.y + threadIdx.y;\n",
        "\n",
        "  int index = local_i * size + local_j;\n",
        "\n",
        "  if (local_i < size && local_j < size) {\n",
        "    C[index] = A[index] + 10;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "  const int size = 6;\n",
        "  float A[size][size], C[size][size];\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    for (int j = 0; j < size; j++) {\n",
        "      A[i][j] = static_cast<float>(i) + static_cast<float>(j);\n",
        "    }\n",
        "  }\n",
        "\n",
        "  float *d_A, *d_C;\n",
        "\n",
        "  cudaMalloc(&d_A, (size * size) * sizeof(float));\n",
        "  cudaMalloc(&d_C, (size * size) * sizeof(float));\n",
        "\n",
        "  dim3 threadsPerBlock(size - 1, size - 1);\n",
        "  dim3 blocksPerGrid(((size + threadsPerBlock.x - 1) / threadsPerBlock.x),\n",
        "                    (((size + threadsPerBlock.y - 1) / threadsPerBlock.y)));\n",
        "\n",
        "  cudaMemcpy(d_A, A, (size * size) * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  Map2DBlock<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_C, size);\n",
        "\n",
        "  cudaMemcpy(C, d_C, (size * size) * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(d_A);\n",
        "  cudaFree(d_C);\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    for (int j = 0; j < size; j++) {\n",
        "      assert(C[i][j] == A[i][j] + 10);\n",
        "    }\n",
        "  }\n",
        "\n",
        "  std::cout << \"2D mapping successful\" << std::endl;\n",
        "  return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tQ8vGqgX0ft",
        "outputId": "c8f9f90e-4314-4620-8dfb-e768e379a9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing map2d_block.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc map2d_block.cu -o map2d_block\n",
        "!./map2d_block\n",
        "!compute-sanitizer ./map2d_block"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_2QPua6dYOH",
        "outputId": "e1d187c6-13d4-410f-dfb9-3232b920258c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D mapping successful\n",
            "========= COMPUTE-SANITIZER\n",
            "2D mapping successful\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile shared.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cassert>\n",
        "\n",
        "__global__ void Shared(float* A, float* C, float size) {\n",
        "  extern __shared__ float sharedMem[];\n",
        "\n",
        "  int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int local_i = threadIdx.x;\n",
        "\n",
        "  if (i < size) {\n",
        "    sharedMem[local_i] = A[i];\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "  if (i < size) {\n",
        "    C[i] = sharedMem[local_i] + 10;\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int size = 5;\n",
        "  float A[size], C[size];\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    A[i] = static_cast<float>(i);\n",
        "  }\n",
        "\n",
        "  float *d_A, *d_C;\n",
        "\n",
        "  cudaMalloc(&d_A, size * sizeof(float));\n",
        "  cudaMalloc(&d_C, size * sizeof(float));\n",
        "\n",
        "  cudaMemcpy(d_A, A, size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  int threadsPerBlock = size - 1;\n",
        "  int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "  int shared_size = threadsPerBlock * sizeof(float);\n",
        "\n",
        "  Shared<<<blocksPerGrid, threadsPerBlock, shared_size>>>(d_A, d_C, size);\n",
        "\n",
        "  cudaMemcpy(C, d_C, size * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(d_A);\n",
        "  cudaFree(d_C);\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    assert(C[i] == A[i] + 10);\n",
        "  }\n",
        "\n",
        "  std::cout << \"Shared successful!\" << std::endl;\n",
        "  return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI5pI-93dopw",
        "outputId": "7e99a700-99a5-4799-e4eb-b8ea26f6be16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing shared.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc shared.cu -o shared\n",
        "!./shared\n",
        "!compute-sanitizer ./shared"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfuoidOzmEK0",
        "outputId": "d5d97a4a-8899-4416-877a-27fc2eb502cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shared successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Shared successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pooling.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cassert>\n",
        "\n",
        "__global__ void Pooling(float* A, float* C, float size) {\n",
        "  extern __shared__ float sharedMem[];\n",
        "  int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int local_i = threadIdx.x;\n",
        "\n",
        "  if (i < size) {\n",
        "    sharedMem[local_i] = A[i];\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "  if (local_i - 2 >= 0 && i < size) {\n",
        "    C[i] = sharedMem[local_i - 2] + sharedMem[local_i - 1] + sharedMem[local_i];\n",
        "  }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  const int size = 4;\n",
        "  float A[size], C[size];\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    A[i] = static_cast<float>(i);\n",
        "  }\n",
        "\n",
        "  float *d_A, *d_C;\n",
        "\n",
        "  cudaMalloc(&d_A, size * sizeof(float));\n",
        "  cudaMalloc(&d_C, size * sizeof(float));\n",
        "\n",
        "  cudaMemcpy(d_A, A, size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  int threadsPerBlock = size;\n",
        "  int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "  int shared_size = threadsPerBlock * sizeof(float);\n",
        "\n",
        "  Pooling<<<blocksPerGrid, threadsPerBlock, shared_size>>>(d_A, d_C, size);\n",
        "\n",
        "  cudaMemcpy(C, d_C, size * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(d_A);\n",
        "  cudaFree(d_C);\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    if (i >= 2) {\n",
        "        assert(C[i] == A[i] + A[i-1] + A[i-2]);\n",
        "    }\n",
        "  }\n",
        "\n",
        "  std::cout << \"Pooling successful!\" << std::endl;\n",
        "  return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJrhSkAZmNJg",
        "outputId": "ceafc44a-67ab-4905-f6bf-b1373c4b6968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing pooling.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc pooling.cu -o pooling\n",
        "!./pooling\n",
        "!compute-sanitizer ./pooling\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjGkzHNjwboE",
        "outputId": "c0341463-f604-4fae-cfdb-8827b9009b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pooling successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Pooling successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dot_product.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cassert>\n",
        "\n",
        "__global__ void DotProduct(float* A, float* B, float* C, float size) {\n",
        "  extern __shared__ float sharedMem[];\n",
        "  int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int local_i = threadIdx.x;\n",
        "\n",
        "  if (i < size) {\n",
        "    sharedMem[local_i] = A[i] * B[i];\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "  if (local_i == 0) {\n",
        "    int sum = 0;\n",
        "    for (int k = 0; k < size; k++) {\n",
        "      sum = sum + sharedMem[k];\n",
        "    }\n",
        "    C[0] = sum;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "  const int size = 8;\n",
        "  float A[size], B[size], C[1];\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    A[i] = i;\n",
        "  }\n",
        "\n",
        "  for (int j = 0; j < size; j++) {\n",
        "    B[j] = j;\n",
        "  }\n",
        "\n",
        "  float *d_A, *d_B, *d_C;\n",
        "\n",
        "  cudaMalloc(&d_A, size * sizeof(float));\n",
        "  cudaMalloc(&d_B, size * sizeof(float));\n",
        "  cudaMalloc(&d_C, sizeof(float));\n",
        "\n",
        "  cudaMemcpy(d_A, A, size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_B, B, size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  int threadsPerBlock = size;\n",
        "  int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "  int shared_size = threadsPerBlock * sizeof(float);\n",
        "\n",
        "  DotProduct<<<blocksPerGrid, threadsPerBlock, shared_size>>>(d_A, d_B, d_C, size);\n",
        "\n",
        "  cudaMemcpy(C, d_C, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(d_A);\n",
        "  cudaFree(d_B);\n",
        "  cudaFree(d_C);\n",
        "\n",
        "  int expected_dot_product = 0;\n",
        "  for (int k = 0; k < size; k++) {\n",
        "    expected_dot_product += A[k] * B[k];\n",
        "  }\n",
        "  assert(C[0] == expected_dot_product);\n",
        "\n",
        "  std::cout << \"Dot product successful!\" << std::endl;\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "-THvJO5qwusY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf17a63-1eab-413b-f39e-9c700a10730d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dot_product.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc dot_product.cu -o dot_product\n",
        "!./dot_product\n",
        "!compute-sanitizer ./dot_product"
      ],
      "metadata": {
        "id": "Rj7qQTmaMtuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e40b9ea0-1fc8-47f0-ead9-53e296f41990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dot product successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Dot product successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 1d_conv.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cassert>\n",
        "\n",
        "const int TPB = 8;\n",
        "const int MAX_CONV = 4;\n",
        "const int TPB_MAX_CONV = TPB + MAX_CONV;\n",
        "\n",
        "__global__ void Conv1D(float* A, float* B, float* C, int a_size, int b_size) {\n",
        "  extern __shared__ float sharedMem[];\n",
        "\n",
        "  float* shared_a = sharedMem;\n",
        "  float* shared_b = sharedMem + TPB_MAX_CONV;\n",
        "\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int local_i = threadIdx.x;\n",
        "\n",
        "  if (i < a_size) {\n",
        "    shared_a[local_i] = A[i];\n",
        "  }\n",
        "\n",
        "  if (local_i < b_size) {\n",
        "    shared_b[local_i] = B[local_i];\n",
        "  }\n",
        "  else {\n",
        "    int local_i2 = local_i - b_size;\n",
        "    int i2 = i - b_size;\n",
        "    if (i2 + TPB < a_size && local_i2 < b_size) {\n",
        "      shared_a[local_i2 + TPB] = A[i2 + TPB];\n",
        "    }\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "  int sum = 0;\n",
        "  for (int j = 0; j < b_size; j++) {\n",
        "    if (i + j < a_size) {\n",
        "      sum += shared_a[local_i + j] * shared_b[j];\n",
        "    }\n",
        "  }\n",
        "\n",
        "  if (i < a_size) {\n",
        "    C[i] = sum;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "  const int size = 5;\n",
        "\n",
        "  float A[size], B[size-2], C[1];\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    A[i] = i;\n",
        "  }\n",
        "\n",
        "  for (int j = 0; j < size-2; j++) {\n",
        "    B[j] = j;\n",
        "  }\n",
        "\n",
        "  float *d_A, *d_B, *d_C;\n",
        "\n",
        "  cudaMalloc(&d_A, size * sizeof(float));\n",
        "  cudaMalloc(&d_B, (size - 2) * sizeof(float));\n",
        "  cudaMalloc(&d_C, size * sizeof(float));\n",
        "\n",
        "  cudaMemcpy(d_A, A, size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_B, B, (size - 2) * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  int blocksPerGrid = (size + TPB - 1) / TPB;\n",
        "\n",
        "  int shared_size_a = sizeof(float) * (TPB + MAX_CONV);\n",
        "  int shared_size_b = sizeof(float) * MAX_CONV;\n",
        "\n",
        "  Conv1D<<<blocksPerGrid, TPB, shared_size_a + shared_size_b>>>(\n",
        "    d_A, d_B, d_C, size, (size - 2)\n",
        "  );\n",
        "\n",
        "  cudaMemcpy(C, d_C, size * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(d_A);\n",
        "  cudaFree(d_B);\n",
        "  cudaFree(d_C);\n",
        "\n",
        "  float host_C[] = {5, 8, 11, 4, 0};\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    assert(host_C[i] == C[i]);\n",
        "  }\n",
        "\n",
        "  std::cout << \"1D Convolution successful!\" << std::endl;\n",
        "\n",
        "  return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1hKxiyvN1ij",
        "outputId": "b8c95802-061a-4c65-b97f-e19a83bcd973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting 1d_conv.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc 1d_conv.cu -o 1d_conv\n",
        "!./1d_conv\n",
        "!compute-sanitizer ./1d_conv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLvZO6fyUlA3",
        "outputId": "442fda38-e92f-4a35-8589-cee1d5f04e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1D Convolution successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "1D Convolution successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prefix_sum.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cassert>\n",
        "#include <math.h>\n",
        "\n",
        "__global__ void PrefixSum(float* A, float* C, int size) {\n",
        "  extern __shared__ float cache[];\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int local_i = threadIdx.x;\n",
        "\n",
        "  if (i < size) {\n",
        "    cache[local_i] = A[i];\n",
        "  }\n",
        "  __syncthreads();\n",
        "\n",
        "  for (int p = 0; p < 3; p++) {\n",
        "    int k = pow(2, p);\n",
        "    if (local_i % (k * 2) == 0 && local_i + k < blockDim.x) {\n",
        "      cache[local_i] += cache[local_i + k];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "  if (i < size) {\n",
        "    C[i] = cache[local_i];\n",
        "  }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "  const int size = 5;\n",
        "\n",
        "  float A[size], C[size];\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    A[i] = i;\n",
        "  }\n",
        "\n",
        "  float *d_A, *d_C;\n",
        "\n",
        "  cudaMalloc(&d_A, size * sizeof(float));\n",
        "  cudaMalloc(&d_C, size * sizeof(float));\n",
        "\n",
        "  cudaMemcpy(d_A, A, size * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  int threadsPerBlock = size;\n",
        "  int blocksPerGrid = (size + threadsPerBlock - 1) / threadsPerBlock;\n",
        "  int shared_size = threadsPerBlock * sizeof(float);\n",
        "\n",
        "  PrefixSum<<<blocksPerGrid, threadsPerBlock, shared_size>>>(\n",
        "    d_A, d_C, size\n",
        "  );\n",
        "\n",
        "  cudaMemcpy(C, d_C, size * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(d_A);\n",
        "  cudaFree(d_C);\n",
        "\n",
        "  assert(C[0] == 10);\n",
        "\n",
        "  std::cout << \"Prefix sum successful!\" << std::endl;\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "_hIlHnlxV_2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756c314f-a0f1-4178-df5f-3f699db488c6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting prefix_sum.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc prefix_sum.cu -o prefix_sum\n",
        "!./prefix_sum\n",
        "!compute-sanitizer ./prefix_sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SlyuDl2kgRK",
        "outputId": "653817e6-2484-4584-eebd-0d9005b81086"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prefix sum successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Prefix sum successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile axis_sum.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cassert>\n",
        "#include <math.h>\n",
        "\n",
        "__global__ void AxisSum(float* A, float* C, int size) {\n",
        "  extern __shared__ float cache[];\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int local_i = threadIdx.x;\n",
        "  int batch = blockIdx.y;\n",
        "\n",
        "  int flat_index = batch * size + i;\n",
        "\n",
        "  if (i < size) {\n",
        "    cache[local_i] = A[flat_index];\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int p = 0; p < 3; p++) {\n",
        "      int k = pow(2, p);\n",
        "      if (local_i % (k * 2) == 0 && local_i + k < size) {\n",
        "        cache[local_i] += cache[local_i + k];\n",
        "      }\n",
        "      __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (i < size) {\n",
        "      C[batch] = cache[local_i];\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "  const int size = 5;\n",
        "  const int numBatches = 1;\n",
        "\n",
        "  float A[size * numBatches], C[numBatches];\n",
        "\n",
        "  for (int j = 0; j < numBatches; j++) {\n",
        "    for (int i = 0; i < size; i++) {\n",
        "      A[j * size + i] = i;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  float *d_A, *d_C;\n",
        "\n",
        "  cudaMalloc(&d_A, size * numBatches * sizeof(float));\n",
        "  cudaMalloc(&d_C, numBatches * sizeof(float));\n",
        "\n",
        "  cudaMemcpy(d_A, A, size * numBatches * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  dim3 threadsPerBlock(size, 1);\n",
        "  dim3 blocksPerGrid(1, numBatches);\n",
        "  int shared_size = threadsPerBlock.x * sizeof(float);\n",
        "\n",
        "  AxisSum<<<blocksPerGrid, threadsPerBlock, shared_size>>>(d_A, d_C, size);\n",
        "\n",
        "  cudaMemcpy(C, d_C, numBatches * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(d_A);\n",
        "  cudaFree(d_C);\n",
        "\n",
        "  assert(C[0] == 10);\n",
        "\n",
        "  std::cout << \"Axis sum successful!\" << std::endl;\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp_mB6YVknk4",
        "outputId": "b742cda1-c6d3-486c-bda0-fe6f1303cb2a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting axis_sum.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc axis_sum.cu -o axis_sum\n",
        "!./axis_sum\n",
        "!compute-sanitizer ./axis_sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISU7WW3-oI2V",
        "outputId": "5ed52aaa-c663-4acb-c41a-f82339b3be76"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Axis sum successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Axis sum successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matmul.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cassert>\n",
        "\n",
        "const int TPB = 3;\n",
        "\n",
        "__global__ void Matmul(float* A, float* B, float* C, int size) {\n",
        "  extern __shared__ float sharedMem[];\n",
        "  float* a_shared = sharedMem;\n",
        "  float* b_shared = sharedMem + (TPB * TPB);\n",
        "\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "  int local_i = threadIdx.x;\n",
        "  int local_j = threadIdx.y;\n",
        "\n",
        "  float sum = 0;\n",
        "  for (int k = 0; k < size; k += TPB) {\n",
        "    if (i < size && k + local_j < size) {\n",
        "      a_shared[local_i * TPB + local_j] = A[i * size + k + local_j];\n",
        "    }\n",
        "    if (j < size && k + local_i < size) {\n",
        "      b_shared[local_i * TPB + local_j] = B[(local_i + k) * size + j];\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int local_k = 0; local_k < TPB; local_k++) {\n",
        "      if (k + local_k < size) {\n",
        "        sum += a_shared[local_i * TPB + local_k] * b_shared[local_k * TPB + local_j];\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  if (i < size && j < size) {\n",
        "    C[i * size + j] = sum;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "  const int size = 2;\n",
        "  float A[size][size], B[size][size], C[size][size];\n",
        "\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    for (int j = 0; j < size; j++) {\n",
        "      A[i][j] = i * j;\n",
        "      B[i][j] = i + j;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  float *d_A, *d_B, *d_C;\n",
        "  cudaMalloc(&d_A, (size * size) * sizeof(float));\n",
        "  cudaMalloc(&d_B, (size * size) * sizeof(float));\n",
        "  cudaMalloc(&d_C, (size * size) * sizeof(float));\n",
        "\n",
        "  cudaMemcpy(d_A, A, (size * size) * sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_B, B, (size * size) * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  int BpG = (size + TPB - 1) / TPB;\n",
        "  dim3 blocksPerGrid(BpG, BpG);\n",
        "  dim3 threadsPerBlock(TPB, TPB);\n",
        "  int sharedMemSize = 2 * (TPB * TPB) * sizeof(float);\n",
        "\n",
        "  Matmul<<<blocksPerGrid, threadsPerBlock, sharedMemSize>>>(d_A, d_B, d_C, size);\n",
        "\n",
        "  cudaMemcpy(C, d_C, (size * size) * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  cudaFree(d_A);\n",
        "  cudaFree(d_B);\n",
        "  cudaFree(d_C);\n",
        "\n",
        "  assert(C[0][0] == 0);\n",
        "  assert(C[0][1] == 0);\n",
        "  assert(C[1][0] == 1);\n",
        "  assert(C[1][1] == 2);\n",
        "\n",
        "  std::cout << \"Matrix multiplication successful!\" << std::endl;\n",
        "\n",
        "  return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBxBhtvhp93g",
        "outputId": "3aa8db57-dce3-4bf7-f1ca-abc66e3ef1a9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matmul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matmul.cu -o matmul\n",
        "!./matmul\n",
        "!compute-sanitizer ./matmul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7d3y-_Sh5uH",
        "outputId": "d81346ad-1c93-46fa-a5de-b7500d4c78d7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix multiplication successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Matrix multiplication successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cw1DlczbiDiV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}